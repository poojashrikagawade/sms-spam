{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'C:\\Users\\methu\\OneDrive\\Desktop\\smp.csv',encoding='ISO 8859-1',header=None)\n",
    "data = pd.read_csv(r'C:\\Users\\methu\\OneDrive\\Desktop\\smp.csv', encoding = 'latin1',header=None)\n",
    "data.rename(columns={1:'text_message', 0:'v1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>text_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                       text_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4827\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data[['v1','text_message']]\n",
    "data1.dropna(inplace=True)\n",
    "data1['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespaces\n",
    "data1['text_message']=data1['text_message'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the text\n",
    "data1['text_message'] = data1['text_message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "punc = string.punctuation\n",
    "table = str.maketrans('','',punc)\n",
    "data1['text_message']=data1['text_message'].apply(lambda x: x.translate(table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing each message\n",
    "data1['word_tokens']=data1.apply(lambda x: x['text_message'].split(' '),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "data1['cleaned_text'] = data1.apply(lambda x: [word for word in x['word_tokens'] if word not in stopwords.words('english')]\n",
    "                                    ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "ps = PorterStemmer()\n",
    "data1['stemmed']= data1.apply(lambda x: [ps.stem(word) for word in x['cleaned_text']],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove single letter words\n",
    "data1['final_text'] = data1.apply(lambda x: ' '.join([word for word in x['stemmed'] if len(word)>1]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding ham=0 and spam=1\n",
    "data1.loc[data1['v1']=='ham','v1']=0\n",
    "data1.loc[data1['v1']=='spam','v1']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the set in training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,X_test,y,y_test = train_test_split(data1.loc[:,'text_message':],data1['v1'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll create a vocabulary for the training set with word count\n",
    "vocab=defaultdict(int) \n",
    "for text in X['final_text'].values:\n",
    "    for elem in text.split(' '):\n",
    "        vocab[elem]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we look at the types of words in ham and spam.\n",
    "ham_text=' '.join(X.loc[y==0,'final_text'].values)\n",
    "ham_wordcloud = WordCloud(background_color='white',max_words=2000).generate(ham_text)\n",
    "spam_text=' '.join(X.loc[y==1,'final_text'].values)\n",
    "spam_wordcloud = WordCloud(background_color='white',max_words=2000).generate(spam_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text for further calculations\n",
    "X['tokenized_final_text']=X['final_text'].str.split(' ')\n",
    "X_test['tokenized_final_text']=X_test['final_text'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document frequency(number of docs containing word w) and Inverse document frequency(measures rarity of each word)\n",
    "df={}\n",
    "for k in vocab.keys():\n",
    "    df[k]=np.sum(X['tokenized_final_text'].apply(lambda x: 1 if k in x else 0))\n",
    "    \n",
    "# Now we'll calculate the idf score of each word\n",
    "idf = {k:1+np.log((1+X.shape[0]/(1+v))) for k,v in df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf * idf\n",
    "for elem in vocab.keys():\n",
    "    X[elem]= X['tokenized_final_text'].apply(lambda x: x.count(elem)*idf[elem] if elem in x else 0)\n",
    "for elem in vocab.keys():\n",
    "    X_test[elem]= X_test['tokenized_final_text'].apply(lambda x: x.count(elem)*idf[elem] if elem in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('int')\n",
    "y_test = y_test.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3851,    0],\n",
       "       [   0,  608]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X.iloc[:,6:],y)\n",
    "confusion_matrix(y,lr.predict(X.iloc[:,6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[976,   0],\n",
       "       [ 14, 125]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,lr.predict(X_test.iloc[:,6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******logistic regression*************\n",
      "f1 score ---------- 0.9469696969696969\n",
      "accuracy score-------- 0.9874439461883409\n"
     ]
    }
   ],
   "source": [
    "print('******logistic regression*************')\n",
    "print('f1 score ----------',f1_score(y_test,lr.predict(X_test.iloc[:,6:])))\n",
    "print('accuracy score--------',lr.score(X_test.iloc[:,6:],y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3851,    0],\n",
       "       [  45,  563]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=70,random_state=3)\n",
    "rf.fit(X.iloc[:,6:],y)\n",
    "confusion_matrix(y,rf.predict(X.iloc[:,6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[975,   1],\n",
       "       [ 27, 112]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,rf.predict(X_test.iloc[:,6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************random forest***********\n",
      "f1 score----------- 0.8888888888888888\n",
      "accuracy score-------- 0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "print('************random forest***********')\n",
    "print('f1 score-----------',f1_score(y_test,rf.predict(X_test.iloc[:,6:])))\n",
    "print('accuracy score--------',rf.score(X_test.iloc[:,6:],y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
